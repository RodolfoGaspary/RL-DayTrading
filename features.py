import pandas as pd
import ta
import numpy as np

def add_technical_indicators(df):
    """
    Adds technical indicators to the dataframe using the 'ta' library.
    Expects columns: 'high', 'low', 'close', 'volume'
    """
    if df.empty:
        return df
        
    df = df.copy()
    
    # Filter to only necessary columns
    needed_cols = ['open', 'high', 'low', 'close', 'volume']
    # Check if all needed cols are present
    if not all(col in df.columns for col in needed_cols):
        print(f"Error: Missing columns. Have {df.columns}, need {needed_cols}")
        return df
        
    df = df[needed_cols] # Drop extra columns like 'trade_count', 'vwap' which might be NaN
    
    # Ensure columns are numeric
    for col in needed_cols:
        df[col] = pd.to_numeric(df[col])

    # RSI - Relative Strength Index (Momentum)
    df['rsi'] = ta.momentum.rsi(df['close'], window=14)
    
    # MACD - Trend
    macd = ta.trend.MACD(df['close'])
    df['macd'] = macd.macd()
    df['macd_signal'] = macd.macd_signal()
    df['macd_diff'] = macd.macd_diff()
    
    # Bollinger Bands - Volatility
    bollinger = ta.volatility.BollingerBands(df['close'], window=20, window_dev=2)
    df['bb_high'] = bollinger.bollinger_hband()
    df['bb_low'] = bollinger.bollinger_lband()
    df['bb_width'] = (df['bb_high'] - df['bb_low']) / df['close']
    
    # ATR - Average True Range (Volatility - for SL/TP)
    df['atr'] = ta.volatility.average_true_range(df['high'], df['low'], df['close'], window=14)
    
    # SMA/EMA - Trend
    df['sma_20'] = ta.trend.sma_indicator(df['close'], window=20)
    df['ema_50'] = ta.trend.ema_indicator(df['close'], window=50)
    
    # Volume Indicators
    df['obv'] = ta.volume.on_balance_volume(df['close'], df['volume'])
    df['mfi'] = ta.volume.money_flow_index(df['high'], df['low'], df['close'], df['volume'], window=14)
    
    # Trend Strength (Confidence Boosters)
    adx_ind = ta.trend.ADXIndicator(df['high'], df['low'], df['close'], window=14)
    df['adx'] = adx_ind.adx()
    
    # Choppiness Index (Custom or TA) - ta has it in trend or volatility?
    # Actually, ta doesn't have a direct 'chop' but we can use ADX as a proxy or add a simple one.
    # We will use ADX and CCI for trend conviction.
    df['cci'] = ta.trend.cci(df['high'], df['low'], df['close'], window=20)
    
    # Log Returns for model stability
    df['log_return'] = np.log(df['close'] / df['close'].shift(1))
    
    # Drop NaN values generated by indicators (early rows)
    df.dropna(inplace=True)
    
    return df
    
def add_local_sr_features(df, window=12, prefix=""):
    """
    Detects very local support and resistance using rolling max/min.
    window: Number of candles to look back (user suggested a 'dozen or so').
    """
    if df.empty: return df
    df = df.copy()
    
    close_col = f"{prefix}close" if f"{prefix}close" in df.columns else 'close'
    high_col = f"{prefix}high" if f"{prefix}high" in df.columns else 'high'
    low_col = f"{prefix}low" if f"{prefix}low" in df.columns else 'low'

    # Local Resistance (High) and Support (Low)
    df[f'{prefix}local_res'] = df[high_col].rolling(window=window).max()
    df[f'{prefix}local_sup'] = df[low_col].rolling(window=window).min()
    
    # Proximity to S/R (0 = at support, 1 = at resistance)
    range_val = df[f'{prefix}local_res'] - df[f'{prefix}local_sup']
    df[f'{prefix}sr_prox'] = (df[close_col] - df[f'{prefix}local_sup']) / range_val.replace(0, 1e-9)
    
    # Binary flags for "at support" or "at resistance" (within 0.02% of range)
    df[f'{prefix}at_sup'] = (df[close_col] <= df[f'{prefix}local_sup'] * 1.0002).astype(int)
    df[f'{prefix}at_res'] = (df[close_col] >= df[f'{prefix}local_res'] * 0.9998).astype(int)
    
    return df
    
def add_volume_features(df, prefix=""):
    """
    Adds volume spike detection and VWAP proximity.
    """
    if df.empty: return df
    df = df.copy()
    
    vol_col = f"{prefix}volume" if f"{prefix}volume" in df.columns else 'volume'
    close_col = f"{prefix}close" if f"{prefix}close" in df.columns else 'close'
    high_col = f"{prefix}high" if f"{prefix}high" in df.columns else 'high'
    low_col = f"{prefix}low" if f"{prefix}low" in df.columns else 'low'

    # Volume Spike: Current volume relative to 20-period average
    df[f'{prefix}vol_spike'] = df[vol_col] / df[vol_col].rolling(window=20).mean().replace(0, 1e-9)
    
    # VWAP (Simple Approximation if not provided by API)
    if f'{prefix}vwap' not in df.columns:
        tp = (df[high_col] + df[low_col] + df[close_col]) / 3
        df[f'{prefix}vwap'] = (tp * df[vol_col]).cumsum() / df[vol_col].cumsum().replace(0, 1e-9)
    
    # VWAP Proximity
    df[f'{prefix}vwap_prox'] = (df[close_col] - df[f'{prefix}vwap']) / df[f'{prefix}vwap'].replace(0, 1e-9)
    
    return df

def add_leading_indicators(df_qqq, df_spy=None, df_vix=None):
    """
    Adds leading indicator features from SPY and VIX to QQQ dataframe.
    
    Args:
        df_qqq: QQQ dataframe with technical indicators already added
        df_spy: SPY dataframe (optional)
        df_vix: VIX dataframe (optional)
    
    Returns:
        Enhanced QQQ dataframe with leading indicator features
    """
    df = df_qqq.copy()
    
    # Add SPY features if provided
    if df_spy is not None and not df_spy.empty:
        # Align timestamps
        df_spy = df_spy.copy()
        df_spy.columns = [f'spy_{col}' if col not in ['timestamp'] else col for col in df_spy.columns]
        
        # Merge on timestamp (assuming both have timestamp index or column)
        if 'timestamp' in df.columns:
            df = df.merge(df_spy[['timestamp', 'spy_close', 'spy_volume']], on='timestamp', how='left')
        else:
            df = df.join(df_spy[['spy_close', 'spy_volume']], how='left')
        
        # Calculate SPY features
        df['spy_return_1m'] = df['spy_close'].pct_change(1)
        df['spy_return_5m'] = df['spy_close'].pct_change(5)
        df['spy_momentum'] = df['spy_close'] / df['spy_close'].shift(10) - 1
        
        # SPY-QQQ spread and correlation
        df['spy_qqq_spread'] = (df['spy_close'] / df['spy_close'].shift(1)) - (df['close'] / df['close'].shift(1))
        df['spy_qqq_corr'] = df['close'].rolling(20).corr(df['spy_close'])
        
        # SPY volume surge (relative to 20-period average)
        df['spy_volume_surge'] = df['spy_volume'] / df['spy_volume'].rolling(20).mean()
    
    # Add VIX features if provided
    if df_vix is not None and not df_vix.empty:
        df_vix = df_vix.copy()
        df_vix.columns = [f'vix_{col}' if col not in ['timestamp'] else col for col in df_vix.columns]
        
        # Merge on timestamp
        if 'timestamp' in df.columns:
            df = df.merge(df_vix[['timestamp', 'vix_close']], on='timestamp', how='left')
        else:
            df = df.join(df_vix[['vix_close']], how='left')
        
        # Calculate VIX features
        df['vix_level'] = df['vix_close']
        df['vix_change'] = df['vix_close'].pct_change(1)
        df['vix_change_5m'] = df['vix_close'].pct_change(5)
        
        # VIX percentile (relative to 20-day range)
        vix_min = df['vix_close'].rolling(20*390).min()  # 20 days * ~390 minutes
        vix_max = df['vix_close'].rolling(20*390).max()
        df['vix_percentile'] = (df['vix_close'] - vix_min) / (vix_max - vix_min)
        
        # VIX spike detection (>2 std devs above mean)
        vix_mean = df['vix_close'].rolling(20).mean()
        vix_std = df['vix_close'].rolling(20).std()
        df['vix_spike'] = ((df['vix_close'] - vix_mean) / vix_std).clip(lower=0, upper=5)
    
    # Drop NaN values
    df.dropna(inplace=True)
    
    return df

def add_temporal_features(df):
    """
    Adds time-based features to capture intraday patterns.
    Assumes df has a datetime index or timestamp column.
    
    Args:
        df: Dataframe with datetime index or timestamp column
    
    Returns:
        Dataframe with temporal features added
    """
    df = df.copy()
    
    # Ensure we have a datetime index
    if 'timestamp' in df.columns:
        df['dt'] = pd.to_datetime(df['timestamp'])
    elif isinstance(df.index, pd.DatetimeIndex):
        df['dt'] = df.index
    else:
        print("Warning: No datetime index or timestamp column found")
        return df
    
    # Extract time components
    df['hour'] = df['dt'].dt.hour
    df['minute'] = df['dt'].dt.minute
    df['day_of_week'] = df['dt'].dt.dayofweek  # 0=Monday, 4=Friday
    
    # Market session features (assuming 9:30-16:00 ET)
    df['minutes_since_open'] = (df['hour'] - 9) * 60 + (df['minute'] - 30)
    df['minutes_until_close'] = (16 - df['hour']) * 60 - df['minute']
    
    # Binary flags for key periods
    df['is_first_hour'] = ((df['hour'] == 9) & (df['minute'] >= 30)) | (df['hour'] == 10)
    df['is_last_hour'] = (df['hour'] >= 15)
    df['is_lunch'] = (df['hour'] >= 12) & (df['hour'] < 14)
    df['is_monday'] = (df['day_of_week'] == 0).astype(int)
    df['is_friday'] = (df['day_of_week'] == 4).astype(int)
    
    # Cyclical encoding for hour (to preserve circular nature)
    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
    
    # Drop temporary dt column if it was created
    if 'dt' in df.columns and 'timestamp' in df.columns:
        df = df.drop('dt', axis=1)
    
    return df

def create_sequences(df, lookback_window=60, target_horizon=1):
    """
    Prepares sequences for LSTM/Transformer training.
    X: Shape (N, lookback_window, num_features)
    y: Shape (N, ) - Target (e.g., price change or direction)
    """
    # Define features to use for the model
    feature_cols = ['close', 'rsi', 'macd', 'macd_signal', 'bb_width', 'atr', 'log_return', 'adx', 'cci', 'mfi']
    
    # Check if all columns exist
    feature_cols = [c for c in feature_cols if c in df.columns]
    
    data = df[feature_cols].values
    X, y = [], []
    
    for i in range(len(data) - lookback_window - target_horizon):
        X.append(data[i:(i + lookback_window)])
        
        # Target: 1 if Price at (i+window+horizon) > Price at (i+window), else 0 (Binary Classification)
        # OR: Price at horizon (Regression)
        
        current_price = data[i + lookback_window - 1, 0] # Close price is at index 0
        future_price = df['close'].iloc[i + lookback_window + target_horizon - 1]
        
        # Binary Classification Target: 1 if bullish, 0 if bearish
        target = 1 if future_price > current_price else 0
        y.append(target)
        
    return np.array(X), np.array(y)

def add_multi_timeframe_indicators(df, sr_window=12):
    """
    Expects a merged dataframe with columns prefixed by '1m_', '5m_', '15m_', '4h_'.
    Calculates key features for each timeframe including local S/R.
    """
    if df.empty: return df
    df = df.copy()
    
    tfs = ['1m', '5m', '15m', '4h']
    
    for tf in tfs:
        close_col = f'{tf}_close'
        high_col = f'{tf}_high'
        low_col = f'{tf}_low'
        
        if close_col not in df.columns: continue
        
        # Core Indicators per timeframe
        df[f'{tf}_rsi'] = ta.momentum.rsi(df[close_col], window=14)
        
        # MACD
        macd = ta.trend.MACD(df[close_col])
        df[f'{tf}_macd'] = macd.macd()
        df[f'{tf}_macd_signal'] = macd.macd_signal()
        
        # ATR (Volatility)
        df[f'{tf}_atr'] = ta.volatility.average_true_range(df[high_col], df[low_col], df[close_col], window=14)
        
        # Local S/R Features
        df = add_local_sr_features(df, window=sr_window, prefix=f"{tf}_")
        
        # Volume Features
        df = add_volume_features(df, prefix=f"{tf}_")
        
        # Returns
        df[f'{tf}_log_return'] = np.log(df[close_col] / df[close_col].shift(1))

    # Clean up
    df.dropna(inplace=True)
    return df

def create_multi_timeframe_sequences(df, lookback_window=60, target_horizon=1):
    """
    Prepares sequences with 1m, 5m, and 15m features.
    """
    # Expanded feature set
    feature_cols = [
        '5m_close', '5m_rsi', '5m_macd', '5m_atr',
        '1m_rsi', '1m_macd', '1m_log_return',
        '15m_rsi', '15m_macd', '15m_atr'
    ]
    
    # Ensure all exist
    feature_cols = [c for c in feature_cols if c in df.columns]
    
    data = df[feature_cols].values
    X, y = [], []
    
    close_idx = feature_cols.index('5m_close')
    
    for i in range(len(data) - lookback_window - target_horizon):
        X.append(data[i:(i + lookback_window)])
        
        current_price = data[i + lookback_window - 1, close_idx]
        future_price = df['5m_close'].iloc[i + lookback_window + target_horizon - 1]
        
        target = 1 if future_price > current_price else 0
        y.append(target)
        
    return np.array(X), np.array(y)
